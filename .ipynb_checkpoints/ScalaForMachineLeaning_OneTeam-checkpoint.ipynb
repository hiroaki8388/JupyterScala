{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ分析基盤を関数型言語の特性を活かして構築してみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# なんで関数型言語でデータ分析か?\n",
    "データ分析と言えば、pythonやRなどの言語が主流です。理由としては、実装が簡単、ライブラリが豊富というのが主な理由であると思います。 \n",
    "実際にpythonやRで機械学習のライブラリをす多少は叩いてみたこともありますが、初心者が軽く触ってもなんとなく結果がでるのはとてもおもしろかったです。ただし、なんとなく以上に進めない歯痒さや、ライブラリの中身がブラックボックスになっているもどかしさ、そして何より、コードの再利用、テスタビリティー、可読性の観点で、自分の至らなさが原因で、どうしても難しいところがありました。そこで、 **オブジェクト&関数型言語により出来る限りスクラッチで圏と関数、オブジェクト指向の概念を基に実装するチャレンジをすることで、より見晴らしの良いデータ分析の基盤を構築してみようと思いました。**  \n",
    "そのため、この基盤を構築するにあたって、3つの概念をうまく組み合わせる必要があります。\n",
    "- 圏や関数の数学的な概念\n",
    "- データ分析で行われるデータ処理、機械学習、モデルの検証などの概念\n",
    "- オブジェクト指向などの、プログラミングの概念\n",
    "\n",
    "それぞれ3つの全く異なる分野ですが、数学とデータ分析はそれぞれの分野が互いに補完し合い、プログラミングにおいて有益なはたらきをします。\n",
    "圏や関数（正確に言うと、関数は圏の概念を構築しますが、わかりやすさのため、あえて分けています。）は「数学」という強固なフレームワークをもち、そのフレームワークのおかげで、自分で一部だけ実装すれば、**定理に裏付けされたロジックにより**、あとはよしなにやってくれるための基盤をつくることができます。(デザインパターンで言うところの、Templeteパターン、Factoryパターンの使いどころです。)  \n",
    "データ分析は、データの変換と処理により構築されるので、そのような数学的基盤はとても有用です。数学のフレームワークをバックグラウンドに、**具体的に何をするかを**アルゴリズムにより肉付けてきます。    \n",
    "数学（フレームワーク）とデータ分析（アルゴリズム）を仲介役として、関数型プログラミングによって実装する事で、**この２つの概念を結びつけ、再利用性と可読性に秀でたデータ分析基盤を構築するのが、この記事の目的です。**  \n",
    "なお、プログラミング言語としては、Scala(ver2.11.7 ~)を採用します。この言語は関数型としての特性と、オブジェクト指向としての両方の性質をもつので、より、可読性、再利用性の高いプログラミングを行う事ができると期待できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ分析と圏論、関数との相互作用\n",
    "データ分析について、簡単にまとめ、改めて圏論、関数との相性について考えます。\n",
    "\n",
    "## データ分析の区分\n",
    "### 分類 (Classification)\n",
    "履歴データから、分類するためのパターンを抽出する(ex xx度以上の体温の場合、風邪と分類する)\n",
    "\n",
    "### 予測(Prediction)\n",
    "履歴データを参照し、現在の状態から、別の状態を予測（推測）する（ex 大規模の患者データを参考に、現在の健康状態から疾病リスクを予測する）\n",
    "\n",
    "### 最適化(Optimization)\n",
    "全体最適を大規模のデータから構築する\n",
    "\n",
    "### 回帰 (Regression)\n",
    "データに沿った関数を提供する（連続的な分類モデルと同一視出来る）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のどのようなデータ分析も、大まかには以下のプロセスを通して構築されます\n",
    "\n",
    "## データ分析の作業フロー\n",
    "\n",
    "1. 問題の定義\n",
    "2. データの入手\n",
    "3. データのクリーニング（ノイズの除去、規格化など）\n",
    "4. データのパターン分け（必要に応じて）\n",
    "5. 特徴量の選択と、モデルの選択\n",
    "6. モデルの学習と検証　\n",
    "7. モデルの性能の向上\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結局のところ、データ分析とは、 **何らかの観測データ[T]を最終的な分析結果[V]に変換しているにすぎないです。** この考え方は、 **圏論のフレームワークを基に実装する可能性を示唆してます**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 構造と圏\n",
    "Wikiでの圏の定義は以下です。\n",
    "- 対象の類 ob(C)\n",
    "- 対象の間の射の類 hom(C)\n",
    "- 各射 f ∈ hom(C) には始域と呼ばれる対象 a ∈ Ob(C) および終域と呼ばれる対象 b ∈ ob(C) が付随して、\"f は a から b への射である\" と言い、f: a → b と書き表す。\n",
    "- このとき、任意の三対象 a, b, c ∈ ob(C) に対し、射の合成と呼ばれる二項演算 hom(a, b) × hom(b, c) → hom(a, c); (f, g) ↦ g ∘ f が存在して以下の公理を満足する:\n",
    "    - 結合律: f: a → b, g: b → c, h: c → d ならば h ∘ (g ∘ f) = (h ∘ g) ∘ f が成り立つ。\n",
    "    - 単位律: 各対象 x ∈ ob(C) に対して x の恒等射と呼ばれる自己射 idx = 1x: x → x が存在して、任意の射 f: a → x および g: x → b に対して 1x ∘ f = f and g ∘ 1x = g を満たす。\n",
    "\n",
    "諸々ややこしいですが、重要なのは、 **圏とは、集合（集合）と矢印（つながり）で構築される概念なんだな** ということです。\n",
    "- 圏（構造）=集合（データの集合）+相互作用（データ同士のつながり）\n",
    "\n",
    "いわばこれから作るデータの流れの**インフラ基盤を提供してくれる存在**という認識をもつことが出来ればと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalaでデータ分析を始める\n",
    "上に書いたように\n",
    "- データ分析は インプッットデータ=>処理1=>処理2=>...=>アウトプット　と**変換処理をつなげていくことである**\n",
    "- 圏論&関数はデータを変換する流れを構築する**パイプライン**を構築する素晴らしい基盤となる\n",
    "\n",
    "この二つを上手く組み合わせるために、Scalaによりデータ分析パイプラインを構築していきます\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "データ分析はどのような場合も、７つのワークフローに沿って、データの分析がおこなわれいきます。つまり、そのための、モデルを構築していきます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目標として、例えば、元のデータ[T]=>データのサンプル作成[U]=>データの規格化[V]=> データの抽出[W]までを行うワークフローを以下のように定義します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtrait \u001b[36mWorkflow\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trait Workflow[T, U, V, W] extends UsesSampling[T, U] with UsesNormalization[U, V] with UsesAggregation[V, W] {\n",
    "\n",
    "  def ||>(t: T): Try[W] =\n",
    "    for {\n",
    "      u <- sampler |> t   // サンプル作成\n",
    "      v <- normalizer |> u // サンプルデータの規格化\n",
    "      w <- aggregator |> v // 規格化したデータから一部を抽出\n",
    "    } yield w\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルとは\n",
    "\n",
    "\n",
    "- モデルとは、 **特定のシステムから観測されるデータを説明するため**に使用される。対象のデータをを説明するためのパターンをモデルとして構築し、そこから、新たなパターンを構築する  \n",
    "\n",
    "と定義します  \n",
    "Scala(関数型言語)においては、関数と圏の概念により、数学的バックグラウンドに基づいたモデルの基盤をつくっていきます  \n",
    "ここでは圏と関数のよさを活かしたモデリングをしていきます\n",
    "- 圏: データ処理の基盤構造（フレームワーク）を提供\n",
    "- 関数: 圏では運用上難しいところを小回りよく活用するための処理を提供\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 圏論の立場によるモデルの構築\n",
    "数学的には、関数も圏の一部と見なせる、ため圏と関数を分けるのは良くないが、プログラミングの立場からは、その役割が異なる事から意図的に区別してまとめる。大まかには、**圏: 大まかな構造（フレームワーク）を提供、関数: 圏では運用上難しいところを小回りよく活用する**ように役割をかえてつかう\n",
    "- データの操作および連鎖に関して、高度に抽象化されたフレームワークを提供する\n",
    "- 非常に協力だが、反面、高度に抽象化されている故に、小回りが効かない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "データ変換を行う以下のようなモデルを定義します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "その前に、データ処理に何らかのコンテキスト（設定）を注入する必要がある場合を考え、それ用の`case class`を定義します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtrait \u001b[36mConfig\u001b[0m\n",
       "defined \u001b[32mclass \u001b[36mConfigInt\u001b[0m\n",
       "defined \u001b[32mclass \u001b[36mConfigDouble\u001b[0m\n",
       "defined \u001b[32mclass \u001b[36mConfigArrayDouble\u001b[0m\n",
       "defined \u001b[32mobject \u001b[36mConfigNone\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trait Config\n",
    "\n",
    "case class ConfigInt(iParam: Int) extends Config\n",
    "\n",
    "case class ConfigDouble(fParam: Double) extends Config\n",
    "\n",
    "case class ConfigArrayDouble(fParams: Array[Double]) extends Config\n",
    "\n",
    "case object ConfigNone extends Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、データ分析の基盤を構築する`Monad`として、`Transform`を定義します。これは、`|>`に特定の処理を記述することで、`[T:インプットデータ]|>[A:処理済みのデータ] `\n",
    "として、構築します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass \u001b[36mTransform\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abstract class Transform[T, A](config: Config) {\n",
    "  // T:インプットする特徴量のデータ,A:アウトプットされるデータ\n",
    "  self =>\n",
    "  def |> : PartialFunction[T, Try[A]] // データ処理を行うメソッド\n",
    "\n",
    "  def map[B](f: A => B): Transform[T, B] = new Transform[T, B](config) {\n",
    "    override def |> = new PartialFunction[T, Try[B]] {\n",
    "      override def isDefinedAt(t: T) =\n",
    "        self.|>.isDefinedAt(t)\n",
    "\n",
    "      override def apply(t: T): Try[B] = self.|>(t).map(f)\n",
    "    }\n",
    "  }\n",
    "\n",
    "  def flatMap[B](f: A => Transform[T, B]): Transform[T, B] = new Transform[T, B](config) {\n",
    "    override def |> = new PartialFunction[T, Try[B]] {\n",
    "      override def isDefinedAt(t: T) =\n",
    "        self.|>.isDefinedAt(t)\n",
    "\n",
    "      override def apply(t: T): Try[B] = self.|>(t).flatMap(f(_).|>(t))\n",
    "    }\n",
    "  }\n",
    "\n",
    "  def andThen[B](tr: Transform[A, B]): Transform[T, B] = new Transform[T, B](config) {\n",
    "    override def |> = new PartialFunction[T, Try[B]] {\n",
    "      override def isDefinedAt(t: T) =\n",
    "        self.|>.isDefinedAt(t) && tr.|>.isDefinedAt(self.|>(t).get)\n",
    "\n",
    "      override def apply(t: T) = tr.|>(self.|>(t).get)\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 関数の立場によるモデルの構築\n",
    "関数の特性により、小回りが効くモデルを提供します。関数を構築するプロセスは、以下の3つに分解できます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 対象となる問題に対しての変数の宣言\n",
    "- 変数から問題を解くための方程式（モデル）の構築\n",
    "- モデルのインスタンス化と実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 変数の宣言\n",
    "まず、変数を宣言します。Fはベクトルをベクトルに変換する関数を変数に持ち、Gはベクトルを一つの値に変換する関数を変数に持ちます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype \u001b[36mV\u001b[0m\n",
       "defined \u001b[32mtrait \u001b[36mF\u001b[0m\n",
       "defined \u001b[32mtrait \u001b[36mG\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type V=Vector[Double]\n",
    "trait F{val f:V=>V} // R^n=>R^n\n",
    "trait G{val g:V=>Double} // R^n=> R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モデルの定義\n",
    "\n",
    "この２つを関数合成した関数`h=f◦g`をモデルとして定義したい場合、、`class H`は以下のように定義できます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass \u001b[36mH\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class H{self:F with G=>def apply(v:V):Double=g(f(v)) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モデルのインスタンス化\n",
    "上記で抽象化したモデルをインスタンスとして、実現するために、実装をします。これでモデルを実行できました"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mjava.lang._\u001b[0m\n",
       "\u001b[36mh\u001b[0m: \u001b[32mH\u001b[0m with \u001b[32mF\u001b[0m with \u001b[32mG\u001b[0m = cmd13$$user$$anonfun$2$$anon$1@96fb872\n",
       "\u001b[36mres13_2\u001b[0m: \u001b[32mscala\u001b[0m.\u001b[32mDouble\u001b[0m = \u001b[32m30.19287485057736\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import java.lang._\n",
    "val h=new H with F with G{\n",
    "    val f=(v:V)=>v.map(Math.exp) // f:x=>exp(x)\n",
    "    val g = (v:V)=>v.sum// g:x=>Σxi\n",
    "}\n",
    "\n",
    "// モデルのベクトルを代入\n",
    "h(Vector(1.0,2.0,3.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 圏と関数で実際のデータ処理を行う\n",
    "ここから、上記の圏と関数の概念にオブジェクト指向の特性を活かして、実装していきます\n",
    "Scalaでは、`trait`により、**ロジックを注入していく事で、データ分析のワークフローの過程に沿って、動的にモジュールを置換する事が可能になる**  \n",
    "そのため、ここからは上記での圏の概念と関数の概念によるモデリングに加え、オブジェクト指向の考え方を活用するため[MinmalCakePattern](https://qiita.com/pab_tech/items/1c0bdbc8a61949891f1f)を使用する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体例として、データ処理として、\n",
    "- 連続的な値の順列を作成\n",
    "- その順列を[0,1]の間に収まるように規格化\n",
    "- さらにその中から最大の値を抽出する\n",
    "\n",
    "の三つのプロセスを行う必要があるとします"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上で定義したデータ処理プロセスを`Transform`により構築します  \n",
    "まず、MInimakCakePatternによりそれぞれの処理を責務としてもつ変数を定義します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtrait \u001b[36mUsesSampling\u001b[0m\n",
       "defined \u001b[32mtrait \u001b[36mUsesNormalization\u001b[0m\n",
       "defined \u001b[32mtrait \u001b[36mUsesAggregation\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trait UsesSampling[T, A] {\n",
    "  val sampler: Transform[T, A]\n",
    "}\n",
    "\n",
    "trait UsesNormalization[T, A] {\n",
    "  val normalizer: Transform[T, A]\n",
    "}\n",
    "\n",
    "trait UsesAggregation[T, A] {\n",
    "  val aggregator: Transform[T, A]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ処理をそれぞれのフェイズに分解した。これらを組み合わせる事で、ワークフローを構築する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtrait \u001b[36mWorkflow\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// ワークフローの流れを構築\n",
    "trait Workflow[T, U, V, W] extends UsesSampling[T, U] with UsesNormalization[U, V] with UsesAggregation[V, W] {\n",
    "\n",
    "  def ||>(t: T): Try[W] =\n",
    "    for {\n",
    "      u <- sampler |> t\n",
    "      v <- normalizer |> u\n",
    "      w <- aggregator |> v\n",
    "    } yield w\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "これで、処理の流れは構築できました。ここから、ロジックを注入していきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype \u001b[36mDblF\u001b[0m\n",
       "defined \u001b[32mtype \u001b[36mDblArray\u001b[0m\n",
       "\u001b[36msamples\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m100\u001b[0m\n",
       "\u001b[36mnormRatio\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m10\u001b[0m\n",
       "\u001b[36msplits\u001b[0m: \u001b[32mInt\u001b[0m = \u001b[32m4\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// 必要な型とのAiliasと定数を定義\n",
    "type DblF = Double => Double\n",
    "type DblArray = Array[Double]\n",
    "val (samples, normRatio,splits) = (100, 10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtrait \u001b[36mMixInSampling\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// サンプルとして、使用する値を定義\n",
    "trait MixInSampling {\n",
    "  val sampler: Transform[DblF, DblArray] = new Transform[DblF, DblArray](ConfigInt(samples)) {\n",
    "    override def |> : PartialFunction[DblF, Try[DblArray]] = {\n",
    "      case f: DblF => Try(Array.tabulate(samples)(n => f(1.0 * n / samples))) // 0,0.01,0.02,,,1.00までの値をfで変換した要素をもつベクトルを生成\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31mMain.scala:51: type mismatch;",
      " found   : Array[Double]",
      " required: cmd18.this.$ref$cmd14.DblArray",
      "    (which expands to)  Array[Double]",
      "    values.map(x => (x - min) * ratio.toDouble + low)",
      "              ^\u001b[0m",
      "\u001b[31mMain.scala:56: object MinMax does not take type parameters.",
      "      case x: DblArray if (x.nonEmpty) => Try(MinMax[Double](x).normalize())",
      "                                                    ^\u001b[0m"
     ]
    }
   ],
   "source": [
    "// 最大値の最小値で規格化するロジックを持つclass\n",
    "case class MinMax(values:DblArray){\n",
    "\n",
    "  val range = (0.0, 0.0)\n",
    "\n",
    "  // valuesのなかで最小な値をと最大な値を抽出する\n",
    "  protected val minMax = values.foldLeft(range) { (mM, x) => {\n",
    "    val min = mM._1\n",
    "    val max = mM._2\n",
    "    (if (x < min) x else min, if (x > max) x else max)\n",
    "  }\n",
    "  }\n",
    "\n",
    "  val min = minMax._1\n",
    "  val max = minMax._2\n",
    "\n",
    "  //[lox,high]の間で正規化する yi-low=(xi-x_low/(x_hig-x_low)(high-low))\n",
    "  def normalize(low: Double = 0.0, high: Double = 1.0): DblArray = {\n",
    "    val ratio = (high - low) / (max - min)\n",
    "    values.map(x => (x - min) * ratio.toDouble + low)\n",
    "  }\n",
    "}\n",
    "\n",
    "// 上で定義したMinMaxにより、値を[0,1]の間に規格化する\n",
    "trait MixInNormalizer {\n",
    "  val normalizer: Transform[DblArray, DblArray] = new Transform[DblArray, DblArray](ConfigDouble(normRatio)) {\n",
    "    override def |> = {\n",
    "      case x: DblArray if (x.nonEmpty) => Try(MinMax[Double](x).normalize())\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtrait \u001b[36mMixInAggregator\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// 規格化した値の中から、一番大きな値のindexを抽出するロジックを定義\n",
    "trait MixInAggregator {\n",
    "  val aggregator = new Transform[DblArray, Int](ConfigInt(splits)) {\n",
    "    override def |> : PartialFunction[DblArray, Try[Int]] = {\n",
    "      case x: DblArray if x.nonEmpty => Try(x.indices.find(x(_) == 1.0).getOrElse(-1)) // 規格化したデータのうち最大の値（=1.0）の値のindexを取得する\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "これらのロジックをWorkflowに注入することで、データ処理を実行します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  val workflow= new Workflow[DblF,DblArray,DblArray,Int] with MixInSampling with MixInNormalizer with MixInAggregator\n",
    "\n",
    "  val g=(x:Double)=>Math.log(x+1.0)+Random.nextDouble // サンプルデータをこの関数により変換する\n",
    "\n",
    "  val out=workflow ||> g\n",
    "\n",
    "  println(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Success(96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96番目の値が最大値でした"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MInimalCakePatternにより、ロジックの変更、注入、分解が非常に簡単になっているので、例えば、「最後のAggregationを除いて、サンプルのロジックを少し変えたい」\n",
    "と言う場合は、以下のように少し変えるだけで簡単にできます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtrait \u001b[36mWorkflowWithoutAgr\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// 例えば、サンプルのロジックを入れ替え、aggregationを外したい場合\n",
    "// 入れ替えることも、使い回す事も、拡張する事も自由自在\n",
    "// ワークフローの流れを構築\n",
    "trait WorkflowWithoutAgr[T, U, V] extends UsesSampling[T, U] with UsesNormalization[U, V]{\n",
    "\n",
    "  def ||>(t: T): Try[V] =\n",
    "    for {\n",
    "      u <- sampler |> t\n",
    "      v <- normalizer |> u\n",
    "    } yield v\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      ""
     ]
    }
   ],
   "source": [
    "trait MixInSampling2 {\n",
    "  val sampler: Transform[DblF, DblArray] = new Transform[DblF, DblArray](ConfigInt(samples)) {\n",
    "    override def |> : PartialFunction[DblF, Try[DblArray]] = {\n",
    "      case f: DblF => Try(Array.tabulate(samples)(n => f(Math.exp(1.0 * n / samples)))) // サンプルをexpにかけるように少し変更\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  val workflowWithoutAgr=new WorkflowWithoutAgr[DblF,DblArray,DblArray] with MixInSampling2 with MixInNormalizer\n",
    "\n",
    "  val out2 = workflowWithoutAgr ||> g\n",
    "  println(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように簡単に付け替え、と修正ができました。データ処理の部品化により、より簡単にデータ処理のパイプラインを構築することができます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まとめ\n",
    "- 圏と関数でデータの流れを制御するパイプラインのインフラ基盤を構築した\n",
    "- そのインフラ基盤にデータ分析のアルゴリズムを注入した\n",
    "- さらにオブジェクト指向により、そのパイプラインの構築やメンテナンスを容易にした\n",
    "\n",
    "ことが、できました。とはいえ、まだデータの前処理の段階なので、次回は単純ベイズモデルを例に、データの前処理から、モデルの精度検証までまとめます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# リファレンス\n",
    "- [Scala for MachineLeaning](https://www.amazon.co.jp/dp/B00R6585KO/ref=dp-kindle-redirect?_encoding=UTF8&btkr=1)\n",
    "- [ScalaDesignPattern](https://www.amazon.co.jp/dp/B017XSFKW4/ref=dp-kindle-redirect?_encoding=UTF8&btkr=1)                             \n",
    "- [Scalaにおける最適なDependency Injectionの方法を考察する](https://qiita.com/pab_tech/items/1c0bdbc8a61949891f1f)      \n",
    "- [圏論勉強会@ワークスアプリケーション](http://nineties.github.io/category-seminar/#/)\n",
    "                                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
